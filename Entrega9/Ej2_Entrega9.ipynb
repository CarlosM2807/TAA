{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "389f8649",
   "metadata": {},
   "source": [
    "# ENTREGA 9 - TAA\n",
    "### Alumno: Carlos Martín Sanz\n",
    "### Profesor: Teodoro Calongue Cano"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fa2853",
   "metadata": {},
   "source": [
    "# ####################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdff6162",
   "metadata": {},
   "source": [
    "### EJERCICIO 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c760d008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# El conjunto de datos de BOSTON se encuentra en el paquete SKLEARN\n",
    "# por ello voy a leerlo \n",
    "\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "# Paquete que dice el enunciado de la practica\n",
    "\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f0431ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Atributos:  [[6.3200e-03 1.8000e+01 2.3100e+00 ... 1.5300e+01 3.9690e+02 4.9800e+00]\n",
      " [2.7310e-02 0.0000e+00 7.0700e+00 ... 1.7800e+01 3.9690e+02 9.1400e+00]\n",
      " [2.7290e-02 0.0000e+00 7.0700e+00 ... 1.7800e+01 3.9283e+02 4.0300e+00]\n",
      " ...\n",
      " [6.0760e-02 0.0000e+00 1.1930e+01 ... 2.1000e+01 3.9690e+02 5.6400e+00]\n",
      " [1.0959e-01 0.0000e+00 1.1930e+01 ... 2.1000e+01 3.9345e+02 6.4800e+00]\n",
      " [4.7410e-02 0.0000e+00 1.1930e+01 ... 2.1000e+01 3.9690e+02 7.8800e+00]]\n",
      "-------------------\n",
      "Clases:  [24.  21.6 34.7 33.4 36.2 28.7 22.9 27.1 16.5 18.9 15.  18.9 21.7 20.4\n",
      " 18.2 19.9 23.1 17.5 20.2 18.2 13.6 19.6 15.2 14.5 15.6 13.9 16.6 14.8\n",
      " 18.4 21.  12.7 14.5 13.2 13.1 13.5 18.9 20.  21.  24.7 30.8 34.9 26.6\n",
      " 25.3 24.7 21.2 19.3 20.  16.6 14.4 19.4 19.7 20.5 25.  23.4 18.9 35.4\n",
      " 24.7 31.6 23.3 19.6 18.7 16.  22.2 25.  33.  23.5 19.4 22.  17.4 20.9\n",
      " 24.2 21.7 22.8 23.4 24.1 21.4 20.  20.8 21.2 20.3 28.  23.9 24.8 22.9\n",
      " 23.9 26.6 22.5 22.2 23.6 28.7 22.6 22.  22.9 25.  20.6 28.4 21.4 38.7\n",
      " 43.8 33.2 27.5 26.5 18.6 19.3 20.1 19.5 19.5 20.4 19.8 19.4 21.7 22.8\n",
      " 18.8 18.7 18.5 18.3 21.2 19.2 20.4 19.3 22.  20.3 20.5 17.3 18.8 21.4\n",
      " 15.7 16.2 18.  14.3 19.2 19.6 23.  18.4 15.6 18.1 17.4 17.1 13.3 17.8\n",
      " 14.  14.4 13.4 15.6 11.8 13.8 15.6 14.6 17.8 15.4 21.5 19.6 15.3 19.4\n",
      " 17.  15.6 13.1 41.3 24.3 23.3 27.  50.  50.  50.  22.7 25.  50.  23.8\n",
      " 23.8 22.3 17.4 19.1 23.1 23.6 22.6 29.4 23.2 24.6 29.9 37.2 39.8 36.2\n",
      " 37.9 32.5 26.4 29.6 50.  32.  29.8 34.9 37.  30.5 36.4 31.1 29.1 50.\n",
      " 33.3 30.3 34.6 34.9 32.9 24.1 42.3 48.5 50.  22.6 24.4 22.5 24.4 20.\n",
      " 21.7 19.3 22.4 28.1 23.7 25.  23.3 28.7 21.5 23.  26.7 21.7 27.5 30.1\n",
      " 44.8 50.  37.6 31.6 46.7 31.5 24.3 31.7 41.7 48.3 29.  24.  25.1 31.5\n",
      " 23.7 23.3 22.  20.1 22.2 23.7 17.6 18.5 24.3 20.5 24.5 26.2 24.4 24.8\n",
      " 29.6 42.8 21.9 20.9 44.  50.  36.  30.1 33.8 43.1 48.8 31.  36.5 22.8\n",
      " 30.7 50.  43.5 20.7 21.1 25.2 24.4 35.2 32.4 32.  33.2 33.1 29.1 35.1\n",
      " 45.4 35.4 46.  50.  32.2 22.  20.1 23.2 22.3 24.8 28.5 37.3 27.9 23.9\n",
      " 21.7 28.6 27.1 20.3 22.5 29.  24.8 22.  26.4 33.1 36.1 28.4 33.4 28.2\n",
      " 22.8 20.3 16.1 22.1 19.4 21.6 23.8 16.2 17.8 19.8 23.1 21.  23.8 23.1\n",
      " 20.4 18.5 25.  24.6 23.  22.2 19.3 22.6 19.8 17.1 19.4 22.2 20.7 21.1\n",
      " 19.5 18.5 20.6 19.  18.7 32.7 16.5 23.9 31.2 17.5 17.2 23.1 24.5 26.6\n",
      " 22.9 24.1 18.6 30.1 18.2 20.6 17.8 21.7 22.7 22.6 25.  19.9 20.8 16.8\n",
      " 21.9 27.5 21.9 23.1 50.  50.  50.  50.  50.  13.8 13.8 15.  13.9 13.3\n",
      " 13.1 10.2 10.4 10.9 11.3 12.3  8.8  7.2 10.5  7.4 10.2 11.5 15.1 23.2\n",
      "  9.7 13.8 12.7 13.1 12.5  8.5  5.   6.3  5.6  7.2 12.1  8.3  8.5  5.\n",
      " 11.9 27.9 17.2 27.5 15.  17.2 17.9 16.3  7.   7.2  7.5 10.4  8.8  8.4\n",
      " 16.7 14.2 20.8 13.4 11.7  8.3 10.2 10.9 11.   9.5 14.5 14.1 16.1 14.3\n",
      " 11.7 13.4  9.6  8.7  8.4 12.8 10.5 17.1 18.4 15.4 10.8 11.8 14.9 12.6\n",
      " 14.1 13.  13.4 15.2 16.1 17.8 14.9 14.1 12.7 13.5 14.9 20.  16.4 17.7\n",
      " 19.5 20.2 21.4 19.9 19.  19.1 19.1 20.1 19.9 19.6 23.2 29.8 13.8 13.3\n",
      " 16.7 12.  14.6 21.4 23.  23.7 25.  21.8 20.6 21.2 19.1 20.6 15.2  7.\n",
      "  8.1 13.6 20.1 21.8 24.5 23.1 19.7 18.3 21.2 17.5 16.8 22.4 20.6 23.9\n",
      " 22.  11.9]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carlosmartin/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Primero cargo el fichero de datos y luego separo las clases de los\n",
    "# atributos\n",
    "\n",
    "datosBoston = load_boston()\n",
    "\n",
    "X = datosBoston.data\n",
    "Y = datosBoston.target\n",
    "\n",
    "print(\"Atributos: \",X)\n",
    "print(\"-------------------\")\n",
    "print(\"Clases: \",Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddaf2ce3",
   "metadata": {},
   "source": [
    "#### Ahora aplicando el método de validacion cruzada con K=10, y con la funcion SGDRegressor,  aplicando una serie de parametros que indica el enunciado, y  obtener una tabla con la tasa de acierto y el coeficiente R² "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b20201d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 1.80000000e-01, 6.78152493e-02, ...,\n",
       "        2.87234043e-01, 1.00000000e+00, 8.96799117e-02],\n",
       "       [2.35922539e-04, 0.00000000e+00, 2.42302053e-01, ...,\n",
       "        5.53191489e-01, 1.00000000e+00, 2.04470199e-01],\n",
       "       [2.35697744e-04, 0.00000000e+00, 2.42302053e-01, ...,\n",
       "        5.53191489e-01, 9.89737254e-01, 6.34657837e-02],\n",
       "       ...,\n",
       "       [6.11892474e-04, 0.00000000e+00, 4.20454545e-01, ...,\n",
       "        8.93617021e-01, 1.00000000e+00, 1.07891832e-01],\n",
       "       [1.16072990e-03, 0.00000000e+00, 4.20454545e-01, ...,\n",
       "        8.93617021e-01, 9.91300620e-01, 1.31070640e-01],\n",
       "       [4.61841693e-04, 0.00000000e+00, 4.20454545e-01, ...,\n",
       "        8.93617021e-01, 1.00000000e+00, 1.69701987e-01]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Primero normalizamos los datos\n",
    "\n",
    "X = MinMaxScaler().fit_transform(X)\n",
    "X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "983f4194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora defino las particiones que se van a realizar en la validacion\n",
    "# cruzada \n",
    "\n",
    "cv = KFold(n_splits = 10)\n",
    "\n",
    "# Y tambien el regresor lineal con las condiciones que nos dice el enu\n",
    "# nciado de la practica\n",
    "\n",
    "regLi = SGDRegressor(max_iter=5000, tol=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3d850b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y ahora creo un dataframe que va a contener la tasa de acierto\n",
    "# y el coeficiente R² para cada una de las particiones de la validacion\n",
    "# cruzada\n",
    "\n",
    "tablaFinal = pd.DataFrame( columns=[\"Tasa acierto\",\"R^2\"])\n",
    "tablaFinal.index.name = \"Particion\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ac62bdec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tasa acierto</th>\n",
       "      <th>R^2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Particion</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.77274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.646146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.72549</td>\n",
       "      <td>-0.228689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.607843</td>\n",
       "      <td>0.602562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.607843</td>\n",
       "      <td>0.589149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.72549</td>\n",
       "      <td>0.736162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.467765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.24</td>\n",
       "      <td>0.081749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.34</td>\n",
       "      <td>-0.468577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.62</td>\n",
       "      <td>0.417519</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Tasa acierto       R^2\n",
       "Particion                       \n",
       "0             0.764706   0.77274\n",
       "1             0.764706  0.646146\n",
       "2              0.72549 -0.228689\n",
       "3             0.607843  0.602562\n",
       "4             0.607843  0.589149\n",
       "5              0.72549  0.736162\n",
       "6                 0.72  0.467765\n",
       "7                 0.24  0.081749\n",
       "8                 0.34 -0.468577\n",
       "9                 0.62  0.417519"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AHora creamos el codigo necesario\n",
    "\n",
    "i = 0\n",
    "\n",
    "for train_index, test_index in cv.split(X,Y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "    \n",
    "    # Ahora entrenamos el regresor lineal que hemos creado antes\n",
    "    \n",
    "    regLi.fit(X_train, Y_train)\n",
    "    \n",
    "    # Predecimos utilizando las instancias del test\n",
    "    \n",
    "    y_predict = regLi.predict(X_test)\n",
    "\n",
    "    # Hallamos R^2\n",
    "    \n",
    "    R2 = regLi.score(X_test, Y_test)\n",
    "    \n",
    "    # Y la tasa de acierto\n",
    "    \n",
    "    tasa_acierto = np.sum(np.abs(np.divide(y_predict, Y_test) -1) < 0.15 )/Y_test.shape[0]\n",
    "    tablaFinal.loc[i,:] = [tasa_acierto,R2]\n",
    "    i = i+1\n",
    "    \n",
    "tablaFinal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43939c60",
   "metadata": {},
   "source": [
    "#### Ahora una vez creada la tabla, nos piden obtener la media y la desviacion tipica de ambas columnas, para ello voy a utilizar  la funcion mean y std encargadas de hallar la media y la desviacion tipica respectivamente de todo el dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec171cb",
   "metadata": {},
   "source": [
    "##### MEDIA DATAFRAME: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4387a9a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tasa acierto    0.611608\n",
       "R^2             0.361653\n",
       "dtype: float64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tablaFinal.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bebdc4",
   "metadata": {},
   "source": [
    "##### DESVIACION TIPICA DATAFRAME :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "71b67015",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tasa acierto    0.181514\n",
       "R^2             0.425635\n",
       "dtype: float64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tablaFinal.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76098eb8",
   "metadata": {},
   "source": [
    "### BREVE CONCLUSION "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b6192b",
   "metadata": {},
   "source": [
    "#### Los resultados obtenidos no son muy buenos ya que la tasa media de aciertos obtenida 0.597725 (59.77%) no es un valor alto, si no que es mas bien bajo y ademas la media de R^2 es bastante baja, aunque el valor de la desviacion tipica es \"medianamente grande\" lo cual indica que aunque el valor de la media de R^2 sea pequeño es variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd64239",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
